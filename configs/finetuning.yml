

epochs: 6
batch_size: 512

lr: 0.001
weight_decay: 1e-5

num_workers: 24

emb_size: 256
heads: 8
depth: 4
n_channels: 19
n_classes: 1

early_stopping_patience: 10
save_every: 5
resume: false


dataset_path: "../../Datasets/chb_mit/data"
pretrained_ckpt: ./logs/pretrain_emb_mask/model_epoch_70.pt

save_dir: ./checkpoints_finetuning
log_dir: ./logs/finetuning_chb_mit

finetune_mode: "frozen_encoder"  # oppure: "from_scratch", "full_finetune", "frozen_encoder" 